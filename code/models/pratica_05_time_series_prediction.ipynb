{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clonando o repositório com os dados do problema"
      ],
      "metadata": {
        "id": "qxfyxeYd07p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r datasets\n",
        "!git clone https://github.com/renansantosmendes/datasets.git"
      ],
      "metadata": {
        "id": "pnb1aqikAWbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando o otimizador"
      ],
      "metadata": {
        "id": "a0w6nZ3-04Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install adabelief-tf --quiet"
      ],
      "metadata": {
        "id": "KYfQ7rTcdEK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazendo os imports das libs necessárias"
      ],
      "metadata": {
        "id": "fEJRTafO01A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from tensorflow import keras\n",
        "from adabelief_tf import AdaBeliefOptimizer\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random"
      ],
      "metadata": {
        "id": "bp6cyST3AeBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lendo os dados e armazenando em uma lista"
      ],
      "metadata": {
        "id": "nZQ4i0W-0xHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "root = './datasets/timeserie_covid'\n",
        "files = os.listdir('./datasets/timeserie_covid')\n",
        "files.sort()\n",
        "data_list = [pd.read_csv(os.path.join(root, file_name), sep=';') for file_name in files]"
      ],
      "metadata": {
        "id": "CIqdrw3lDEt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenando os dados do arquivo"
      ],
      "metadata": {
        "id": "egNE0ZnD0ppN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat(data_list[:], axis=0)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ehKqCDUT-xHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dando uma olhada no dataset"
      ],
      "metadata": {
        "id": "oruUyWSE0bAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nus8i0GT8DCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processando o dado"
      ],
      "metadata": {
        "id": "RplkL9pH0TYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = data[data['regiao'] == 'Brasil']['casosNovos']\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform([[i] for i in dataset])"
      ],
      "metadata": {
        "id": "vrrP40XdAkwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando o dado em treino e teste"
      ],
      "metadata": {
        "id": "pgXMdaKh0Xcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))"
      ],
      "metadata": {
        "id": "8TwGSeEkArTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        " \n",
        "def plot_convergence(hist: tf.keras.callbacks.History, \n",
        "                     metric_name:str) -> None:\n",
        "  figure = plt.gcf()\n",
        "  figure.set_size_inches((15, 5))\n",
        "  figure.patch.set_facecolor('darkgrey')\n",
        "  \n",
        "  ax = plt.axes()\n",
        "  ax.set_facecolor(\"darkgrey\")\n",
        "  \n",
        "  plt.xlabel('Epoch', fontsize=14)\n",
        "  plt.xticks(fontsize=14)\n",
        "  plt.ylabel(metric_name.title(), fontsize=14)\n",
        "  plt.yticks(fontsize=14)\n",
        "\n",
        "  plt.plot(range(1, len(hist.history[metric_name.lower()]) + 1), \n",
        "           hist.history[metric_name.lower()], marker='o', linewidth=3, \n",
        "           markersize=12)\n",
        "  plt.plot(range(1, len(hist.history[f'val_{metric_name.lower()}']) + 1), \n",
        "           hist.history[f'val_{metric_name.lower()}'], marker='X', linewidth=3, \n",
        "           markersize=12)\n",
        "  plt.legend([metric_name.title(), f'Validation {metric_name.title()}'], \n",
        "             fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "def reset_seeds():\n",
        "   np.random.seed(123) \n",
        "   python_random.seed(123)\n",
        "   tf.random.set_seed(1234)"
      ],
      "metadata": {
        "id": "47uaaI4EAxQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "ada_belief = AdaBeliefOptimizer(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "9D6jvZE9XXvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando o dado"
      ],
      "metadata": {
        "id": "8AzCNoiq1MLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 15\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
      ],
      "metadata": {
        "id": "Uhcjl7bLAvCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando, compilando e treinando o modelo"
      ],
      "metadata": {
        "id": "TUHZn0BP1Imj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "reset_seeds() \n",
        "model = Sequential()\n"
      ],
      "metadata": {
        "id": "6NKbl94nAzGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6g_hsUqh5o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotando a convergência"
      ],
      "metadata": {
        "id": "xCsDV_NA2LTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_convergence(hist, 'loss')"
      ],
      "metadata": {
        "id": "-qNC_Cz-VLjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazendo as predições para os dados"
      ],
      "metadata": {
        "id": "Tsd7oDW-2Sc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform([testY])\n",
        "\n",
        "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "id": "JBXYBF__A1Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vendo a série prevista pela rede"
      ],
      "metadata": {
        "id": "EQqlGX9g2ZSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iy-_WjaNA3Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cKolM3GCC73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
